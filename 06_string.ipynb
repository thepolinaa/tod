{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа со строковыми значениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы:\n",
    "* Макрушин С.В. Лекция \"Работа со строковыми значениям\"\n",
    "* https://pyformat.info/\n",
    "* https://docs.python.org/3/library/re.html\n",
    "    * https://docs.python.org/3/library/re.html#flags\n",
    "    * https://docs.python.org/3/library/re.html#functions\n",
    "* https://pythonru.com/primery/primery-primeneniya-regulyarnyh-vyrazheniy-v-python\n",
    "* https://kanoki.org/2019/11/12/how-to-use-regex-in-pandas/\n",
    "* https://realpython.com/nltk-nlp-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Вывести на экран данные из словаря `obj` построчно в виде `k = v`, задав формат таким образом, чтобы знак равенства оказался на одной и той же позиции во всех строках. Строковые литералы обернуть в кавычки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = {\n",
    "    \"home_page\": \"https://github.com/pypa/sampleproject\",\n",
    "    \"keywords\": \"sample setuptools development\",\n",
    "    \"license\": \"MIT\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Написать регулярное выражение,которое позволит найти номера групп студентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Евгения гр.ПМ19-1\n",
       "1         Илья пм 20-4\n",
       "2            Анна 20-3\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = pd.Series([\"Евгения гр.ПМ19-1\", \"Илья пм 20-4\", \"Анна 20-3\"])\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Разбейте текст формулировки задачи 2 на слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Форматирование строк"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Загрузите данные из файла `recipes_sample.csv` (__ЛР2__) в виде `pd.DataFrame` `recipes` При помощи форматирования строк выведите информацию об id рецепта и времени выполнения 5 случайных рецептов в виде таблицы следующего вида:\n",
    "\n",
    "    \n",
    "    |      id      |  minutes  |\n",
    "    |--------------------------|\n",
    "    |    61178     |    65     |\n",
    "    |    202352    |    80     |\n",
    "    |    364322    |    150    |\n",
    "    |    26177     |    20     |\n",
    "    |    224785    |    35     |\n",
    "    \n",
    "Обратите внимание, что ширина столбцов заранее неизвестна и должна рассчитываться динамически, в зависимости от тех данных, которые были выбраны. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      id      |  minutes  |\n",
      "|--------------------------|\n",
      "|    40343     |    75     |\n",
      "|    96220     |    135    |\n",
      "|    392229    |    75     |\n",
      "|    499449    |    27     |\n",
      "|    406099    |    70     |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('recipes_sample.csv')\n",
    "df_5 = df.sample(5)\n",
    "max_len_id = max(df_5['id'].astype(str).apply(len))\n",
    "max_len_minutes = max(df_5['minutes'].astype(str).apply(len))\n",
    "\n",
    "id = 'id'\n",
    "minutes = 'minutes'\n",
    "\n",
    "print(f'|{id:^{max_len_id + 8}}|{minutes:^{max_len_minutes + 8}}|')\n",
    "print('|' + '-'*(8 + 9 + len(id) + len(minutes))+ '|')\n",
    "\n",
    "for index, row in df_5.iterrows():\n",
    "  id = row['id']\n",
    "  minutes = row['minutes']\n",
    "  print(f'|{id:^{max_len_id + 8}}|{minutes:^{max_len_minutes + 8}}|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Напишите функцию `show_info`, которая по данным о рецепте создает строку (в смысле объекта python) с описанием следующего вида:\n",
    "\n",
    "```\n",
    "\"Название Из Нескольких Слов\"\n",
    "\n",
    "1. Шаг 1\n",
    "2. Шаг 2\n",
    "----------\n",
    "Автор: contributor_id\n",
    "Среднее время приготовления: minutes минут\n",
    "```\n",
    "\n",
    "    \n",
    "Данные для создания строки получите из файлов `recipes_sample.csv` (__ЛР2__) и `steps_sample.xml` (__ЛР3__). \n",
    "Вызовите данную функцию для рецепта с id `170895` и выведите (через `print`) полученную строку на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes = pd.read_csv('recipes_sample.csv')\n",
    "with open('steps_sample.xml') as f:\n",
    "  ab = BeautifulSoup(f, 'xml')\n",
    "\n",
    "steps_dict = {}\n",
    "\n",
    "for recipe in ab.find_all('recipe'):\n",
    "  recipe_id = int(recipe.id.text)\n",
    "  steps = [step.text for step in recipe.find_all('step')]\n",
    "  steps_dict[recipe_id] = steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сбор значений атрибутов для recipe_id = 170895\n",
    "row = df_recipes[df_recipes['id'] == 170895]\n",
    "\n",
    "name = row['name'].iloc[0]\n",
    "minutes = row['minutes'].iloc[0]\n",
    "author_id = row['contributor_id'].iloc[0]\n",
    "steps = steps_dict[170895]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_info(name: str, steps: list, minutes: int, author_id: int) -> str:\n",
    "  s = ''\n",
    "  s += f'\"{name.title()}\"\\n\\n'\n",
    "\n",
    "  for index, step in enumerate(steps):\n",
    "    s += f'{index+1}. {step.capitalize()}\\n'\n",
    "  s += '-' * 10 + '\\n'\n",
    "  s += f'Автор: {author_id}\\n'\n",
    "  s += f'Среднее время приготовления: {minutes} минут\\n'\n",
    "\n",
    "\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Leeks And Parsnips  Sauteed Or Creamed\"\n",
      "\n",
      "1. Clean the leeks and discard the dark green portions\n",
      "2. Cut the leeks lengthwise then into one-inch pieces\n",
      "3. Melt the butter in a medium skillet , med\n",
      "4. Heat\n",
      "5. Add the garlic and fry 'til fragrant\n",
      "6. Add leeks and fry until the leeks are tender , about 6-minutes\n",
      "7. Meanwhile , peel and chunk the parsnips into one-inch pieces\n",
      "8. Place in a steaming basket and steam 'til they are as tender as you prefer\n",
      "9. I like them fork-tender\n",
      "10. Drain parsnips and add to the skillet with the leeks\n",
      "11. Add salt and pepper\n",
      "12. Gently sautee together for 5-minutes\n",
      "13. At this point you can serve it , or continue on and cream it:\n",
      "14. In a jar with a screw top , add the half-n-half and arrowroot\n",
      "15. Shake 'til blended\n",
      "16. Turn heat to low under the leeks and parsnips\n",
      "17. Pour in the arrowroot mixture , stirring gently as you pour\n",
      "18. If too thick , gradually add the water\n",
      "19. Let simmer for a couple of minutes\n",
      "20. Taste to adjust seasoning , probably an additional 1 / 2 teaspoon salt\n",
      "21. Serve warm\n",
      "----------\n",
      "Автор: 8377\n",
      "Среднее время приготовления: 27 минут\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(show_info(name, steps, minutes, author_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с регулярными выражениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Напишите регулярное выражение, которое ищет следующий паттерн в строке: число (1 цифра или более), затем пробел, затем слова: hour или hours или minute или minutes. Произведите поиск по данному регулярному выражению в каждом шаге рецепта с id 25082. Выведите на экран все непустые результаты, найденные по данному шаблону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шаг 6: ['20 minutes']\n",
      "Шаг 8: ['10 minutes']\n",
      "Шаг 14: ['10 minutes']\n",
      "Шаг 17: ['20 minutes', '30 minutes']\n"
     ]
    }
   ],
   "source": [
    "for index, step in enumerate(steps_dict[25082]):\n",
    "  res = re.findall(r'[1-9]{1}[0-9]+ hour[s]?|[1-9]{1}[0-9]+ minute[s]?', step)\n",
    "  if len(res) != 0 :\n",
    "    print(f'Шаг {index+1}: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Напишите регулярное выражение, которое ищет шаблон вида \"this..., but\" _в начале строки_ . Между словом \"this\" и частью \", but\" может находиться произвольное число букв, цифр, знаков подчеркивания и пробелов. Никаких других символов вместо многоточия быть не может. Пробел между запятой и словом \"but\" может присутствовать или отсутствовать.\n",
    "\n",
    "Используя строковые методы `pd.Series`, выясните, для каких рецептов данный шаблон содержится в тексте описания. Выведите на экран количество таких рецептов и 3 примера подходящих описаний (текст описания должен быть виден на экране полностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "623"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipes['description'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество подходящих описаний: 134\n"
     ]
    }
   ],
   "source": [
    "df_recipes['description'].fillna(' ', inplace=True)\n",
    "df_4 = df[df_recipes['description'].str.contains('^this[\\w\\d\\s]+,[ ]?but', regex=True)]\n",
    "print('Количество подходящих описаний:', df_4.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21528                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              this grilled chicken gets great flavor from the outdoor grill, but cook time outside is quick because it is partially cooked beforehand.  marinating time is not included in the prep or cook time.\n",
       "24245                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                this is a simple, but yet delicious, creamy, baked corn casserole.  it was given to my sister and i from a dear friend.  we do not know where she got the recipe.  we fix this dish quite often around our house.\n",
       "5260     this sounds like a weird combination of ingredients, but it's really good. i adapted this from a higher-fat recipe i found on the internet. it's still not low fat, but at least better for you than the original. delicious left over too! leftovers can be put into a baked potato for another main dish meal, or stir cooked rice and smoked sausage or cooked chicken or ham into it and re-bake it for another casserole. it freezes well for use later on in a potato, or as a soup if you puree it.\\r\\nyou can use real mayo, miracle whip, or the store brand equivalent. also velveeta (4-6 ounces) works as well as cheddar.\\r\\n18 saltines is about 1/2 a sleeve of saltines from the box. you don't have to really measure them exactly. you can also use other crackers that you have such as cheese-its, or ritz types that are a little stale.\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', int(df_4['description'].apply(len).max() + 10))\n",
    "df_4['description'].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. В текстах шагов рецептов обыкновенные дроби имеют вид \"a / b\". Используя регулярные выражения, уберите в тексте шагов рецепта с id 72367 пробелы до и после символа дроби. Выведите на экран шаги этого рецепта после их изменения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix butter , flour , \u0001/\u0002 c\n",
      "sugar and 1-\u0001/\u0002 t\n",
      "vanilla\n",
      "press into greased 9\" springform pan\n",
      "mix cream cheese , \u0001/\u0002 c\n",
      "sugar , eggs and \u0001/\u0002 t\n",
      "vanilla beating until fluffy\n",
      "pour over dough\n",
      "combine apples , \u0001/\u0002 c\n",
      "sugar and cinnamon\n",
      "arrange on top of cream cheese mixture and sprinkle with almonds\n",
      "bake at 350 for 45-55 minutes , or until tester comes out clean\n"
     ]
    }
   ],
   "source": [
    "for step in steps_dict[72367]:\n",
    "  print(re.sub(r'\\d+ / \\d+', '\\1/\\2', step, count=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сегментация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /Users/ilya/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Разбейте тексты шагов рецептов на слова при помощи пакета `nltk`. Посчитайте и выведите на экран кол-во уникальных слов среди всех рецептов. Словом называется любая последовательность алфавитных символов (для проверки можно воспользоваться `str.isalpha`). При подсчете количества уникальных слов не учитывайте регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in 1 / 4 cup butter , saute carrots , onion , celery and broccoli stems for 5 minutes',\n",
       " 'add thyme , oregano and basil',\n",
       " 'saute 5 minutes more']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = steps_dict.values()\n",
    "flat_arr = [item.lower() for sublist in arr for item in sublist]\n",
    "\n",
    "flat_arr[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных слов: 14953\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "toktok = ToktokTokenizer()\n",
    "res = toktok.tokenize(flat_arr)\n",
    "\n",
    "print('Количество уникальных слов:', len(set(filter(str.isalpha, res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Разбейте описания рецептов из `recipes` на предложения при помощи пакета `nltk`. Найдите 5 самых длинных описаний (по количеству _предложений_) рецептов в датасете и выведите строки фрейма, соответствующие этим рецептами, в порядке убывания длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>description</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18408</th>\n",
       "      <td>my favorite buttercream icing for decorating</td>\n",
       "      <td>334113</td>\n",
       "      <td>30</td>\n",
       "      <td>681465</td>\n",
       "      <td>2008-10-30</td>\n",
       "      <td>12.0</td>\n",
       "      <td>this wonderful icing is used for icing cakes and cookies as well as for borders and art work on cakes.  it makes a delicious filling also between the layers of cakes and under fondant icing.  you can make roses but it takes 3 or more days to dry them depending on the humidity. \\r\\n\\r\\nthere are many versions of “buttercream” icing. some are made with eggs and all butter.  some varieties, you have to cook your sugar to a softball stage.  others are 100% shortening or a combination of shortening and butter.\\r\\n\\r\\neach decorator has his or her favorite.  i personally think that the best taste and textured recipe is the one that has you cook your sugar, add to whipped eggs and use pounds of butter per batch. but…. i live in a state that can easily be a 100 degrees for days on end during the summer and you know what butter does on hot days.  it melts! ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>alligator claws  avocado fritters  with chipotle lime dip</td>\n",
       "      <td>287008</td>\n",
       "      <td>45</td>\n",
       "      <td>765354</td>\n",
       "      <td>2008-02-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a translucent golden-brown crust allows the green of the avocado to be seen.  the crispy exterior is a counterpoint to the unctuous interior.  these are a signature dish for me, and the one i most often get requests to make (although my seafood and ricotta stuffed buckwheat pancakes run a close second).\\r\\n\\r\\nthese fritters came about ten years ago when i was shopping for a dinner i was making for a friend who is a cia-trained chef.  i was in a vegetable market and saw these gorgeous avocados that i just knew would be ripe in the next two days.  i tried to think of what i could do with them since a) everyone serves cold avocado, and b) i really am not fond of guacamole.  as i tried to think of what i could make with them that was hot, the work 'fritters' jumped into my head.  having never made a fritter before, i was a little surprised to have tha...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22566</th>\n",
       "      <td>rich barley mushroom soup</td>\n",
       "      <td>328708</td>\n",
       "      <td>60</td>\n",
       "      <td>221776</td>\n",
       "      <td>2008-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is one of the best soups i've ever made and it is even worthy of company.  so simple, yet rich in deep, mushroomy flavor.  the inspiration was zaar #26877, a delicious mushroom rice casserole.  i found i couldn't stop eating the liquid before putting the casserole into the oven and that gave me the idea that the base  would make a delicious soup.  and it does! \\r\\nuse plenty of fresh mushrooms.  i buy them when they are marked 1/2 price at the grocery, as this is a good way to use your 'shrooms that are starting to get dark.  it is the soy sauce that transforms the broth from ho-hum to yum.  i try to use low sodium or home-made no sodium chicken broth so that i can use the soy for the sodium.  there is no sense of \"asian\" in this soup at all.  ( i would not make this without the soy. )  just a little bit adds the depth of flavor and even color...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>chocolate tea</td>\n",
       "      <td>205348</td>\n",
       "      <td>6</td>\n",
       "      <td>428824</td>\n",
       "      <td>2007-01-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i wrote this because there are an astounding lack of chocolate tea recipes on the internet. \\r\\n\\r\\n the first time i heard about chocolate tea was doing a web search on chocolate. there seem to be a few companies out there who sell chocolate tea. i like to stay up late and had run out of coffee. i was in real need for a good tasting caffene beverage. i first thought chocolate tea would be yucky. we are conditioned to accept chocolate with coffee as a rule but not tea. i was very mistaken! \\r\\n\\r\\n tea and chocolate goes very well with each other and it is also very good for your body. both tea and chocolate are loaded with antioxidents. you may however not want to give this to small children because of the caffene. \\r\\n\\r\\n not having a recipe to follow, i created one. (this one) i used these ingredients because i had them on hand and it was quick...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16296</th>\n",
       "      <td>little bunny foo foo cake  carrot cake  with cream cheese frosti</td>\n",
       "      <td>316000</td>\n",
       "      <td>68</td>\n",
       "      <td>689540</td>\n",
       "      <td>2008-07-27</td>\n",
       "      <td>14.0</td>\n",
       "      <td>the first time i made this cake i grated a million pounds of carrots on a knucklebuster.  then they invented cuisinarts!  now it is much faster to shred the carrots on a fine shredding disk and no bloody knuckles!  i have baked it in 8\", 9\", 9x13\" pans so if you want to experiment with pan size it works.  one thing i found was baking and stacking the three layers is tricky.  my favorite way is two 8\" pans for a nice layer cake and an 8\" square pan to put into the freezer for unexpected company. i hope you try this wonderful cake.  update:  in the spirit of carrot cake stories, this cake was invented by a bunny named foo-foo.  he is very famous and even has a hit song which goes like this: sing to the tune of 'down by the station'..........     \\r\\n\\r\\n\\r\\n little bunny foo foo,\\r\\nhopping through the forest,\\r\\nscooping up the field mice,\\r\\nand bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   name  \\\n",
       "18408                      my favorite buttercream icing for decorating   \n",
       "481           alligator claws  avocado fritters  with chipotle lime dip   \n",
       "22566                                         rich barley mushroom soup   \n",
       "6779                                                      chocolate tea   \n",
       "16296  little bunny foo foo cake  carrot cake  with cream cheese frosti   \n",
       "\n",
       "           id  minutes  contributor_id   submitted  n_steps  \\\n",
       "18408  334113       30          681465  2008-10-30     12.0   \n",
       "481    287008       45          765354  2008-02-19      NaN   \n",
       "22566  328708       60          221776  2008-10-03      NaN   \n",
       "6779   205348        6          428824  2007-01-14      NaN   \n",
       "16296  316000       68          689540  2008-07-27     14.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           description  \\\n",
       "18408  this wonderful icing is used for icing cakes and cookies as well as for borders and art work on cakes.  it makes a delicious filling also between the layers of cakes and under fondant icing.  you can make roses but it takes 3 or more days to dry them depending on the humidity. \\r\\n\\r\\nthere are many versions of “buttercream” icing. some are made with eggs and all butter.  some varieties, you have to cook your sugar to a softball stage.  others are 100% shortening or a combination of shortening and butter.\\r\\n\\r\\neach decorator has his or her favorite.  i personally think that the best taste and textured recipe is the one that has you cook your sugar, add to whipped eggs and use pounds of butter per batch. but…. i live in a state that can easily be a 100 degrees for days on end during the summer and you know what butter does on hot days.  it melts! ...   \n",
       "481    a translucent golden-brown crust allows the green of the avocado to be seen.  the crispy exterior is a counterpoint to the unctuous interior.  these are a signature dish for me, and the one i most often get requests to make (although my seafood and ricotta stuffed buckwheat pancakes run a close second).\\r\\n\\r\\nthese fritters came about ten years ago when i was shopping for a dinner i was making for a friend who is a cia-trained chef.  i was in a vegetable market and saw these gorgeous avocados that i just knew would be ripe in the next two days.  i tried to think of what i could do with them since a) everyone serves cold avocado, and b) i really am not fond of guacamole.  as i tried to think of what i could make with them that was hot, the work 'fritters' jumped into my head.  having never made a fritter before, i was a little surprised to have tha...   \n",
       "22566  this is one of the best soups i've ever made and it is even worthy of company.  so simple, yet rich in deep, mushroomy flavor.  the inspiration was zaar #26877, a delicious mushroom rice casserole.  i found i couldn't stop eating the liquid before putting the casserole into the oven and that gave me the idea that the base  would make a delicious soup.  and it does! \\r\\nuse plenty of fresh mushrooms.  i buy them when they are marked 1/2 price at the grocery, as this is a good way to use your 'shrooms that are starting to get dark.  it is the soy sauce that transforms the broth from ho-hum to yum.  i try to use low sodium or home-made no sodium chicken broth so that i can use the soy for the sodium.  there is no sense of \"asian\" in this soup at all.  ( i would not make this without the soy. )  just a little bit adds the depth of flavor and even color...   \n",
       "6779   i wrote this because there are an astounding lack of chocolate tea recipes on the internet. \\r\\n\\r\\n the first time i heard about chocolate tea was doing a web search on chocolate. there seem to be a few companies out there who sell chocolate tea. i like to stay up late and had run out of coffee. i was in real need for a good tasting caffene beverage. i first thought chocolate tea would be yucky. we are conditioned to accept chocolate with coffee as a rule but not tea. i was very mistaken! \\r\\n\\r\\n tea and chocolate goes very well with each other and it is also very good for your body. both tea and chocolate are loaded with antioxidents. you may however not want to give this to small children because of the caffene. \\r\\n\\r\\n not having a recipe to follow, i created one. (this one) i used these ingredients because i had them on hand and it was quick...   \n",
       "16296  the first time i made this cake i grated a million pounds of carrots on a knucklebuster.  then they invented cuisinarts!  now it is much faster to shred the carrots on a fine shredding disk and no bloody knuckles!  i have baked it in 8\", 9\", 9x13\" pans so if you want to experiment with pan size it works.  one thing i found was baking and stacking the three layers is tricky.  my favorite way is two 8\" pans for a nice layer cake and an 8\" square pan to put into the freezer for unexpected company. i hope you try this wonderful cake.  update:  in the spirit of carrot cake stories, this cake was invented by a bunny named foo-foo.  he is very famous and even has a hit song which goes like this: sing to the tune of 'down by the station'..........     \\r\\n\\r\\n\\r\\n little bunny foo foo,\\r\\nhopping through the forest,\\r\\nscooping up the field mice,\\r\\nand bo...   \n",
       "\n",
       "       n_ingredients  sentence_count  \n",
       "18408            NaN              76  \n",
       "481              9.0              27  \n",
       "22566           10.0              24  \n",
       "6779             NaN              23  \n",
       "16296            NaN              23  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "df_recipes['sentence_count'] = df_recipes['description'].apply(lambda x : len(tokenizer.tokenize(x))) \n",
    "df_recipes.sort_values('sentence_count', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напишите функцию, которая для заданного предложения выводит информацию о частях речи слов, входящих в предложение, в следующем виде:\n",
    "```\n",
    "PRP   VBD   DT      NNS     CC   VBD      NNS        RB   \n",
    " I  omitted the raspberries and added strawberries instead\n",
    "``` \n",
    "Для определения части речи слова можно воспользоваться `nltk.pos_tag`.\n",
    "\n",
    "Проверьте работоспособность функции на названии рецепта с id 241106.\n",
    "\n",
    "Обратите внимание, что часть речи должна находиться ровно посередине над соотвествующим словом, а между самими словами должен быть ровно один пробел.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(sentence: str) -> str:\n",
    "  tokenizer = word_tokenize(sentence)\n",
    "  tagged_list = pos_tag(tokenizer)\n",
    "\n",
    "  res_word = ''\n",
    "  res_tag = ''\n",
    "\n",
    "  for elem in tagged_list:\n",
    "    word, tag = elem[0], elem[1]\n",
    "    n_spaces = abs(len(word) - len(tag))\n",
    "    if len(word) >= len(tag):\n",
    "      tag = ' ' * (n_spaces//2) + tag + ' ' * (n_spaces - n_spaces//2)\n",
    "    else:\n",
    "      word = ' ' * (n_spaces//2) + tag + ' ' * (n_spaces - n_spaces//2)\n",
    "      \n",
    "    res_tag += tag + ' '\n",
    "    res_word += word + ' '\n",
    "\n",
    "  return '\\n'.join([res_tag, res_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   JJ     NNS    IN     NNS    VBP    JJ   CC   JJ    NNS   \n",
      "eggplant steaks with chickpeas feta cheese and black olives \n"
     ]
    }
   ],
   "source": [
    "sentence = df_recipes[df_recipes['id'] == 241106]['name'].tolist()[0]\n",
    "print(tag(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
